---
title: "Project 1: Exploratory Data Analysis"
date: "03.15.20"
author: "Peyton Love, PLL473"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))
```
```

# Introduction

  This project explores different aspects of Netflix Shows and Movies. I chose to combine two datasets by the variable, title. These datasets were each obtained from Kaggle. The first dataset that I obtained consisted of information about the title, director,cast, rating, release year, type, genre, duration, and country in which the show or movie was produced.The second dataset consists of information regarding the title, maturity rating, release year, user rating score and size. I chose these datasets because I, like many other people my age,spend a good amount of time on Netflix, and am interested in looking more into the details of the movies and shows I watch. More specifically, I was interested to see if there was any relationship between release year of the movie or show and the overally maturity and user rating that it was assigned. From the data obtained, I expected there to be a positive association between the release year and the overall maturity rating as well as the maturity rating and the user rating score. 

---

## Part 1: Tidying

  The two datasets were imported to the global environment then renamed. They were already tidy, so I will demonstrate my use of pivot_wider and pivot longer later in the project. I renamed the data sets under the names "netflix_description" and "netflix_ratings". The first dataset currently contains 12 variables with 6234 observations.The second dataset currently contains 7 variables with 1000 observations.


```{R}
library(tidyverse)
install.packages("RCurl")
library(readxl)
library(ggplot2)
library(cluster)
library(GGally)
```

```{R}
netflix_titles <- read_excel("netflix_titles.xlsx")
Netflix_Shows_2 <- read_excel("Netflix Shows-2.xlsx")
netflix_description <- netflix_titles%>%glimpse()
netflix_ratings <- Netflix_Shows_2%>%glimpse()

```

## Part 2: Joining
  Before joining the two datasets, I dropped the extraneous variables by using the select function and renamed them. The "netflix_description2" dataset now has 3 variables including title,release year,and type. The "netflix_ratings2" dataset also has 3 variables, including title, ratingDescription, and user rating score. The number of observations did not change.I joined the two datasets by the variable, title. I chose to merge via inner-join to ensure that all unmatched rows were dropped. I piped it into the unique function to ensure that there were not any duplicate rows. I also used the na.omit function to ensure that any incomplete cases were removed. A total of 6,103 observations were dropped following joining. This was a result of dropping incomplete rows and making sure that each observation was unique.

```{R}
netflix_description2 <-netflix_description%>%
  select(title,type,release_year)%>%glimpse()
netflix_ratings2 <- netflix_ratings%>%
  select(title,ratingDescription,`user rating score`)%>%glimpse()
```

```{R}
netflix<-inner_join(netflix_ratings2,netflix_description2,by="title")%>%na.omit%>%
  unique()%>%glimpse()

```
## Part 3: Wrangling
  I then generated a number of summary statistics. I first arranged by release year to determine what the oldest movie in the dataset was - it was Grease. I then arranged by rating description, descending, to determine the movie with the highest overall maturity rating. From this I noticed that the movies and shows with the highest maturity ratings were generally newer movies. This prompted me to run a summary function to compare the mean maturity rating descriptions of movies and shows, filtering by before 2010 and after 2010. In comparing the obtained means, it was observed that movies and shows released before 2010 had a lower mean rating description than those released after 2010. I created a new variable using the mutate fuction to categorize the observations by a maturity ranking of high, med, or low. 
  
  I then ran summary statistics for all of my numeric vairables, annalyzing the min, max, 25th and 75th quantile, median, mean, standard deviation, variation, and number of observations. After, I ran a similar function, but grouped by the categorical variables of maturity rating and type. After runing the initial summary statistics, the data was presented under 27 variables. I used the pivot_longer to organize this data by the name and value of each of these variables, then separated into the variable and its corresponding statistic. I then used pivot_wider to assign the types of statistics as variables. By summarizing this data into an easy to understand table, I demonstrated my tidying skills. An interesting observation made from these summary statistics was that there was a far greater number of movies and tv shows that fell within the high maturity rating the categorical variable that I created. The mean release year was found to be 2014, indicating that much of the Netflix content in this dataset comes from more recent years. The user rating scores and rating descriptions had similar means, suggesting that there may be a correlation between these two variables. Finally, I created a correlation table of the numeric variables, in which I determined that the strongest correlation exists between release year and maturity rating description. 
```{R}
netflix%>%arrange(release_year)%>%glimpse()

```

```{R}
netflix%>%arrange(desc(ratingDescription))%>%glimpse()

```

```{R}
netflix%>%group_by(type)%>%filter(release_year>=2010)%>%
  summarise(mean_rating=mean(ratingDescription,na.rm=T))%>%glimpse()
```

```{R}
netflix%>%group_by(type)%>%filter(release_year<2010)%>%
  summarise(mean_rating=mean(ratingDescription,na.rm=T))%>%glimpse()
```

```{R}
netflix%>%select(`user rating score`,ratingDescription)%>%
  summarise_all(mean,na.rm=T)%>%glimpse()
```

```{R}
netflix <- netflix%>%mutate(maturityrating = case_when(ratingDescription>70 ~ "high",40<=ratingDescription & ratingDescription<=70 ~ "med", ratingDescription<40 ~ "low"))%>%na.omit%>%unique()%>%glimpse()
```

```{R}
netflix %>%select(ratingDescription,releaseyear=release_year,`user rating score`) %>% 
  summarise_each(funs(min = min, 
                      quant25 = quantile(., 0.25), 
                      median = median, 
                      quant75 = quantile(., 0.75), 
                      max = max,
                      mean = mean, 
                      sd = sd,
                      var = var,
                      count=n()))%>%
  pivot_longer(contains("_"),names_to="temp", values_to="value")%>%
  separate(temp,into=c("variable","stat"),sep="_")%>%
  pivot_wider(names_from = "stat",names_repair = "check_unique", values_from="value")
```

```{R}
netflix %>%group_by(type,maturityrating)%>%select(ratingDescription,releaseyear=release_year,`user rating score`) %>% 
  summarise_each(funs(min = min, 
                      quant25 = quantile(., 0.25), 
                      median = median, 
                      quant75 = quantile(., 0.75), 
                      max = max,
                      mean = mean, 
                      sd = sd,
                      var = var,
                      count=n()))%>%
  pivot_longer(contains("_"),names_to="temp", values_to="value")%>%
  separate(temp,into=c("variable","stat"),sep="_")%>%
  pivot_wider(names_from = "stat",names_repair = "check_unique", values_from="value")
```

```{R}
cor_netflix<-netflix%>% select_if(is.numeric)
cor_netflix%>%cor()
```

## Part 4: Visualizing
  The first plot I created, titled "Movie Rating by Release Year", explores the relationship between release year and user rating score. I added a trend line using geom_smooth which demonstrates that there is a possible correlation between release year and user rating score. This information corresponds to the data obtained from the correlation table in the previous section. In this plot, I also filtered the type to ensure that this represented only data from movies. I added tick marks to the y-axis, by setting the minumin as 0, maximum as 120, and breaks as 5. The data points were colored by maturity rating to allow us to observe the overall distribution of maturity ratings among the movies as well. This data supported my previous observation of higher maturity rated movies generally having later release years. 
  
  The second plot that I created, titled "Number of Movies and Shows by Maturity Rating Since 2014" explores the growth of movies and tv shows in the different maturity categories. The graph was created geom_bar to help visualize the overall number of movies and tv shows in each category. The plot was also faceted by year and help demonstrate the changes in numbers of the last 6 years. The color of the bars are representative of the type of Netflix content, either movies or TV shows. This helped to demonstrate that most of the recent releases found in this dataset are TV shows. This plot also demonstrated that the high maturity rating category experienced the most growth in the last 6 years.
  
  The third plot I created, title "Average User Rating by Maturity Level" explored the relationship between maturity level and the user ratings for each Netflix show or movie. I used the stat=summary function to plot the mean user rating scores for each maturity category. I created this plot using geom_bar, and rearranged the x-axis labels from high, low, med to high, med, low. I used dodge for the position to allow the means of the movies and tv shows to be compared side by side for each maturity category. The high maturity category had the overall highest mean user rating for both movies and tv shows. 
  
  To create my final plot, a heatmap, I first created a dataset of only numeric variable, titled "tidycor". I then created the heatmap,titled "Correlation of Netflix Numeric Variables", which explores the correlations between the numeric variable in the dataset. From this plot, it appears that release year and maturity rating description have the strongest correlation while user rating score and release year have the weakest correlation. 

```{R}
netflix%>%filter(type=="Movie")%>%ggplot(aes(x = release_year, y = `user rating score`)) + geom_point(aes(col=maturityrating))+
  theme(plot.title = element_text(hjust = 0.5))+ 
  guides(fill=guide_legend(title="Maturity Rating"))+ 
  ggtitle("Movie Rating by Release Year") +  ylab("Rating") + 
  xlab("Release Year") + labs(col="Maturity") + 
  geom_smooth(method=lm,se=F) + scale_y_continuous(breaks=seq(0,120,5))
```

```{R}
netflix%>%filter(release_year>=2014)%>%ggplot(aes(x = factor(maturityrating, level = c('high', 'med', 'low')), fill=type))+
  geom_bar(width=0.2)+ theme(plot.title = element_text(hjust = 0.5),axis.text.x = element_text(angle=45,hjust=1),legend.position="bottom")+
  ggtitle("Number of Movies and Shows by Maturity Rating Since 2014")+
  xlab("Maturity Rating")+ ylab("Count")+facet_wrap(~release_year)+labs(fill = "Type")
```

```{R}
netflix%>%ggplot(aes(x = factor(maturityrating, level = c('high', 'med', 'low')), fill=type))+
  geom_bar(aes(y=`user rating score`), stat="summary", fun.y="mean",position="dodge") +
  theme(plot.title = element_text(hjust = 0.5),legend.position="bottom")+
  ggtitle("Average User Rating by Maturity Level")+
  xlab("Maturity Rating")+
  ylab("User Rating")+labs(fill = "Type")
```

```{R}
tidycor<-netflix%>%select_if(is.numeric)%>%cor()%>%as.data.frame%>%
  rownames_to_column%>%
  pivot_longer(-1,names_to="name",values_to="correlation")
tidycor
```

```{R}
tidycor%>%ggplot(aes(rowname,name,fill=correlation))+
  geom_tile()+xlab("Variable 1")+ylab("Variable 2")+ labs(fill="Correlation")+ geom_text(aes(label=round(correlation,2)),color = "black", size = 4) + scale_fill_gradient(low="white", high="seagreen") + 
  ggtitle("Correlation of Netflix Numeric Variables") +
  theme(plot.title = element_text(hjust = 0.5))
```

## Part 5: Dimensionality Reduction
  I performed PAM on my three numeric variables. I first created a dataset titled "pam_netflix" that included the three numeric variables of my "netflix" dataset. To determine the optimal number of clusters, I created an empty vector titled "sil_width" then created a for-loop to compute the average silhouette width for k= 2:10. I then plotted it and determined the optimal number of clusters from the elbow of the plot to be 2. I then clustered the object into the environment as "pam1", using the optimal number of clusters as 2. I summarized the clusters and found the means using the summarize_if function. 
  
  I computed the final medoids of the clusters to be Mighty Morphin Power Rangers for the first cluster and Quantico for the second cluster. These observations were most representative of the clusters. The accuracy with PAM was determined to be 79% after creating a dataset titled "final" in which the cluster variable was created, which assigned each observation to one of the clusters. A confusion matrix was then created and titled "confmat" which was then used with the round and sum functions to calculate the accuracy of PAM. To visualize the pairwise combinations of the three variables, ggpairs was used. Release year and maturity rating description had the strongest overall correlation out of all the variable pairs. Finally, the average silhouette widths were analyzed to determine the strength of the structures. A weak structure was found in cluster 1, but a reasonable structure was found in cluster 2. 

```{R}
pam_netflix<-netflix%>%select_if(is.numeric)%>%glimpse()
```

```{R}
sil_width<-vector()
for(i in 2:10){
  pam_fit <- pam(pam_netflix, k = i)
  sil_width[i] <- pam_fit$silinfo$avg.width}
ggplot()+geom_line(aes(x=1:10,y=sil_width))+scale_x_continuous(name="k",breaks=1:10)
```

```{R}
pam1<-netflix%>%select_if(is.numeric)%>%pam(2)
pam1
```

```{R}
pamclust<-netflix %>% mutate(cluster=as.factor(pam1$clustering))
pamclust %>% group_by(cluster) %>% summarize_if(is.numeric,mean,na.rm=T)
```

```{R}
netflix[pam1$id.med,]
```

```{R}
final<-netflix%>%mutate(cluster=as.factor(pam1$clustering))
confmat<-final%>%group_by(maturityrating)%>%count(cluster)%>%arrange(desc(n))%>%pivot_wider(names_from="cluster",values_from="n",values_fill = list('n'=0))
confmat
round(sum(diag(as.matrix(confmat[,2:3])))/sum(confmat[,2:3]),3)
```

```{R}
netflix %>% mutate(cluster=as.factor(pam1$clustering)) %>% 
  ggpairs(columns = c("ratingDescription","user rating score","release_year"), aes(color=cluster))
```



```{R, echo=F}
## DO NOT DELETE THIS BLOCK!
sessionInfo()
Sys.time()
Sys.info()
```